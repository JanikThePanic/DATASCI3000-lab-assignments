{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P6bAuoTZ_g3"
   },
   "source": [
    "# Assignment 4 - Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H-Yv6NgaAp6"
   },
   "source": [
    "## Grade: 100 pts + 10 Bonus \n",
    "\n",
    "This notebook contains the questions for Assignment 4. \n",
    "\n",
    "You must upload this completed Jupyter Notebook file as your submission (other file types are not permitted and will result in a grade of 0).***\n",
    "\n",
    "* If you have trouble running neural network models on your laptop, you can use online platforms, like **[Google Colab](https://colab.research.google.com/)**.\n",
    "* All Figures should have a x- and y-axis label and an appropriate title.\n",
    "**Ensure that your code runs correctly by choosing \"Kernel -> Restart and Cell -> Run All\" before submitting.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are allowed to use other libraries as needed\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input \n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n",
    "#add other imports here if any (for example, pytorch)\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaD6nkpfZ1zY"
   },
   "source": [
    "## Data set \n",
    "As modern vehicles have lots of connectivity, protecting in-vehicle network from cyber-attacks is an important issue. Controller Area Network (CAN) is the standard protocol for the in-vehicle network. But, the lack of security features in the CAN protocol makes vehicles vulnerable to attacks. The message injection attack is a representative attack type which injects fabricated messages to deceive electronic control unit (ECUs) or cause malfunctions. Through this notebook, you will develop ML modeles to detect different types of CAN attacks and protect vehicle networks. \n",
    "\n",
    "### Source\n",
    "The dataset (CAN-intrusion-dataset-10000.csv) has been constructed by logging CAN traffic via the OBD-II port from a real vehicle while message injection attacks were performing. The classification goal is to distinguish cyber-attacks and normal samples by classifying the data samples. The dataset includes over 10,000 records and 10 attributes (including the target variable \"Label\").\n",
    "\n",
    "### Variables\n",
    "The definitions of the attributes are as followss.\n",
    "\n",
    "* CAN ID : identifier of CAN message.\n",
    "* DATA[0~7] : data value (byte), ranging from 0 to 255. They have been converted from hexadecimal numbers to decimal numbers.  \n",
    "* Label : 0 indicates 'Normal', and 1 indicates an attack (including DoS, Fuzzy, Gear, or RPM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ils9GU09Z1za"
   },
   "source": [
    "## Question 1: Load Datasets (15pts)\n",
    "A) Load the Dataset CAN-intrusion-dataset-10000.csv \n",
    "\n",
    "B) Split the data into equals-sized training and test sets (use a random_state = 1, and do not shuffle the data).  \n",
    "\n",
    "C) How many observations do you have in your training set?  \n",
    "\n",
    "D) How many observations for each class in your training set?\n",
    "\n",
    "E) Z-standarize the input features of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1A) \n",
    "df = pd.read_csv('CAN-intrusion-dataset-10000.csv') # Reading the dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1B) \n",
    "X = df.drop(columns=['Label']) # Using all attributes except 'Label' as predictors\n",
    "y = df['Label'] # Predicting Label\n",
    "# Splitting the data in equal-sized training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in the training set: 5000\n"
     ]
    }
   ],
   "source": [
    "# Q1C) \n",
    "# Using .shape to display the number of rows / observations in the dataset\n",
    "train_observations_count = X_train.shape[0]\n",
    "print(\"Number of observations in the training set:\", train_observations_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for each class in the training set:\n",
      " Label\n",
      "0    4284\n",
      "1     716\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Q1D) \n",
    "# Using the .value_counts() function to find the number of normal samples and cyber-attack samples\n",
    "train_class_counts = y_train.value_counts()\n",
    "print(\"Number of observations for each class in the training set:\\n\", train_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q1E) \n",
    "# Using StandardScaler() to standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1tPRpxyZ1zh"
   },
   "source": [
    "## Question 2: Logistic Regression (20pts)\n",
    "A) Build a L1-regularized logistic regression model to all the training data, and then get the predicted labels for each item of the test set. \n",
    "\n",
    "B) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "C) Print out the model execution time (including both training and testing time) in milliseconds. Please keep two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q2A)\n",
    "# Start the timer\n",
    "start_time = t.time()\n",
    "\n",
    "# Initialize the Logistic Regression model with L1 penalty (as opposed to the default L2 penalty)\n",
    "# 'liblinear' is a solver that is best suited for L1 regularization.\n",
    "# A solver is an algorithm used to find the optimal parameters (weights) for the logistic regression model.\n",
    "# Random state is clarified as 1\n",
    "log_reg = LogisticRegression(penalty='l1', solver='liblinear', random_state=1)\n",
    "\n",
    "# Training the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Label\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Stop the timer\n",
    "end_time = t.time()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = (end_time - start_time) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.98\n",
      "Recall: 0.56\n",
      "F1 Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "### Q2B) \n",
    "# Find precision, recall, and F1 score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print precision, recall, and F1 score to 2 decimal places\n",
    "print(\"Precision:\", round(precision, 2))\n",
    "print(\"Recall:\", round(recall, 2))\n",
    "print(\"F1 Score:\", round(f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time (ms): 91.33\n"
     ]
    }
   ],
   "source": [
    "### Q2C) \n",
    "# Print execution time to 2 decimal places\n",
    "print(\"Execution Time (ms):\", round(execution_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJKS46WTZ1zp"
   },
   "source": [
    "## Question 3: Single Layer Neural Networks (30 pts)\n",
    "In this task we aim to build models with better performance, using \"deep\" learning. __You may use PyTorch or Keras libraries for building deep learning models.__ \n",
    "\n",
    "A) Implement a single-layer neural network model that is used to classify the CAN intrusion data samples into normal and anomalous classes (0: normal, 1: attack). Use the standarized training set from Q1E) to train the network.\n",
    "\n",
    "The details of the model are as follows:\n",
    "* Use a Sigmoid as the output layer acitivation function to enable non-linearity. \n",
    "* Use the binary cross-entropy loss as a training criterion.\n",
    "* Use Stochastic gradient descent optimizer with a learning rate of 0.1.\n",
    "* Run the model for 10 iterations/epochs.\n",
    "\n",
    "B) Record the loss for each iteration, and make a plot of iterations/epochs vs loss(Binary Cross Entropy).\n",
    "\n",
    "C) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "D) Print out the model execution time (including both training and testing time) in milliseconds. Please keep two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3A)Build and Train the Single-Layer Neural Network\n",
    "start_time = time.time()  # Start timer for measuring execution time\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(X_train_scaled.shape[1],)))\n",
    "\n",
    "# Compile the model with specified settings\n",
    "model.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "end_training_time = time.time()  # Record training end time\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "end_testing_time = time.time()  # Record testing end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3B)Plot Loss for Each Epoch\n",
    "loss_values = history.history['loss']\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, loss_values, marker='o', label='Binary Cross-Entropy Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epochs vs Binary Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3C) Calculate Precision, Recall, F1-Score\n",
    "# Predict probabilities for the test set and convert to binary predictions\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q3D)Calculate Execution Time\n",
    "execution_time = (end_testing_time - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"Model Execution Time: {execution_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Multi-Layer Perceptron (MLP) (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Implement a Multi-Layer Perceptron (MLP) model (at least two hidden layers) that is used to classify the CAN intrusion data samples into normal and anomalous classes (0: normal, 1: attack). Use the standarized training set from Q1E) to train the network. \n",
    "The details of the model are as follows:\n",
    "* Each hidden layer have 8 neurons/units. \n",
    "* Use tanh function as the activation function for hidden layers.\n",
    "* Use a Sigmoid as the output layer acitivation function to enable non-linearity.  \n",
    "* Use Stochastic gradient descent optimizer with a learning rate of 0.1.\n",
    "* Run the model for 10 iterations/epochs \n",
    "\n",
    "B) Record the loss for each iteration, and make a plot of iterations/epochs vs loss(Binary Cross Entropy).\n",
    "\n",
    "C) Print out the precision, recall, and F1-score of the test set.\n",
    "\n",
    "D) Print out the model execution time (including both training and testing time) in milliseconds. Please keep two decimal places.\n",
    "\n",
    "E) Written Answer - Use the markdown cell to answer the following:\n",
    "- Compare the performance and training time of your single layer neural network to the MLP model, and discuss the reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q4A)\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming standardized training and test sets are provided as X_train_std, X_test_std, y_train, y_test\n",
    "\n",
    "# Record execution start time\n",
    "start_time = time.time()\n",
    "\n",
    "# A) Build Single-Layer Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(1, activation='sigmoid', input_shape=(X_train_std.shape[1],)))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = SGD(learning_rate=0.1)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "history = model.fit(X_train_std, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Record execution end time\n",
    "end_training_time = time.time()\n",
    "\n",
    "# Evaluate the model on test data\n",
    "_, accuracy = model.evaluate(X_test_std, y_test, verbose=0)\n",
    "\n",
    "# Record test evaluation end time\n",
    "end_testing_time = time.time()\n",
    "\n",
    "# Total execution time in milliseconds\n",
    "execution_time = (end_testing_time - start_time) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q4B)\n",
    "#Record Loss and Plot Epochs vs Loss\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, loss, marker='o', label='Binary Cross-Entropy Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Epochs vs Binary Cross-Entropy Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q4C)\n",
    "# C) Calculate Precision, Recall, F1-Score\n",
    "y_pred = (model.predict(X_test_std) > 0.5).astype(int)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q4D)\n",
    "#Print execution time in milliseconds\n",
    "print(f\"Model Execution Time: {execution_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4E)  \n",
    "Written answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Hyperparameter Optimization (10 Bonus pts)\n",
    "A) Buil a Grid_Search_NN_model that has the same architecture as the MLP model from Question 4. Use grid search to tune two hyperparameters:\n",
    "* The number of neurons on the hidden layers of your MLP model (find the best number among 8, 16, 32). Each hidden layer should have the same number of neurons/nodes, so only one hyperparameter is needed to tune the number of neurons.\n",
    "* Learning rate of the SGD optimizer (find the best value among the two numbers 0.01 and 0.1). \n",
    "\n",
    "B) Implement grid search to identify optimal hyperparameter values, and print out the best hyperparameter values and the best cross-validation accuracy.\n",
    "\n",
    "You can use 3-fold GridSearchCV and KerasClassifier functions on the standarized training set to do this. \n",
    "\n",
    "C) Build the optimized MLP model on the training set by passing the detected best hyperparameter values to the Grid_Search_NN_model. Print out the precision, recall, and F1-score of the optimized MLP model on the test set.\n",
    "\n",
    "PS: If it took too long for you to run this part, you can ignore this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5A)\n",
    "def Grid_Search_NN_model(hidden_neurons = 8, learning_rate = 0.1):\n",
    "    #write function here\n",
    "    \n",
    "    return myGSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5B)\n",
    "# Run gridsearch here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q5C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to add sufficient comments to your code, and run the entire code before submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ECE_9309_Assignment_3_Winter_2022_Blank-AS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
